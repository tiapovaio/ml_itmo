# Unsupervised Learning: кластеризация с KMeans и собственная реализация

В этом проекте исследуется задача кластеризации с применением алгоритма **KMeans** и реализацией собственной версии алгоритма. Цель — сегментировать объекты по лог-преобразованным числовым признакам и проанализировать результат.

---

## Этапы выполнения

### 1. Загрузка и объединение данных

- Загружены два датасета: `data0.csv` и `data1.csv`
- Объединены в единый DataFrame с помощью `pd.concat`

---

### 2. Предобработка данных

- Заполнение пропущенных значений в колонке `medal`
- Кодирование `medal` с помощью `LabelEncoder`
- Логарифмическое преобразование признаков:
  - `views`, `downloads`, `usabilities`, `comments`, `weight`

---

### 3. Визуализация распределений

- Построены гистограммы:
  - До и после лог-преобразования для каждого признака

---

### 4. Обучение модели `KMeans` из sklearn

- Использованы признаки:
  - `normalized_views`, `normalized_downloads`, `normalized_weight`
- Протестированы значения `k` от 2 до 10
- Оценка качества — **Silhouette Score**
- Построен график зависимости Silhouette от количества кластеров
- Выбран `k = 3` как оптимальный

---

### 5. Финальное обучение и визуализация

- Запущен `KMeans` с 3 кластерами
- Добавлены метки кластеров в датафрейм
- Выполнено уменьшение размерности с помощью `PCA`
- Построен 2D-график распределения кластеров

---

### 6. Перебор гиперпараметров

- Перебраны параметры:
  - `n_clusters`: от 2 до 10
  - `max_iter`: от 30 до 150
- Использован `ParameterGrid` для поиска наилучших параметров по **Silhouette Score**

---

### 7. Собственная реализация KMeans

- Реализован класс `MyKMeans`:
  - Использует `numpy` и евклидово расстояние
  - Поддерживает параметры `n_clusters` и `max_iter`
- Проведено обучение и расчёт **Silhouette Score**
- Проведено сравнение с `sklearn.KMeans`

